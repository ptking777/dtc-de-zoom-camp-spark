{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b55f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "\n",
    "from pyspark.sql.functions import col, lag, unix_timestamp\n",
    "from pyspark.sql import functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2dc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cf80ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1.\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "973f9eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-24 03:10:32--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.216.248.84\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.216.248.84|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 733822658 (700M) [text/csv]\n",
      "Saving to: ‘./data/raw/fhvhv/2021/02/fhvhv_tripdata_2021-02.csv’\n",
      "\n",
      "./data/raw/fhvhv/20 100%[===================>] 699.83M  49.3MB/s    in 14s     \n",
      "\n",
      "2022-02-24 03:10:47 (48.8 MB/s) - ‘./data/raw/fhvhv/2021/02/fhvhv_tripdata_2021-02.csv’ saved [733822658/733822658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv \\\n",
    "    -O ./data/raw/fhvhv/2021/02/fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06f3e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvhv_schema = types.StructType([\n",
    "    types.StructField(\"VendorID\", types.IntegerType(), True),\n",
    "    types.StructField(\"pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"passenger_count\", types.IntegerType(), True),\n",
    "    types.StructField(\"trip_distance\", types.DoubleType(), True),\n",
    "    types.StructField(\"RatecodeID\", types.IntegerType(), True),\n",
    "    types.StructField(\"store_and_fwd_flag\", types.StringType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"payment_type\", types.IntegerType(), True),\n",
    "    types.StructField(\"fare_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"extra\", types.DoubleType(), True),\n",
    "    types.StructField(\"mta_tax\", types.DoubleType(), True),\n",
    "    types.StructField(\"tip_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"tolls_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"improvement_surcharge\", types.DoubleType(), True),\n",
    "    types.StructField(\"total_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"congestion_surcharge\", types.DoubleType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1819e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "month = 2\n",
    "\n",
    "\n",
    "\n",
    "input_path = f'data/raw/fhvhv/{year}/{month:02d}/'\n",
    "output_path = f'data/pq/fhvhv/{year}/{month:02d}/'\n",
    "\n",
    "df_fhvhv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e296f2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hvfhs_license_num,StringType,true),StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,StringType,true),StructField(dropoff_datetime,StringType,true),StructField(PULocationID,StringType,true),StructField(DOLocationID,StringType,true),StructField(SR_Flag,StringType,true)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhvhv.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8839759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvhv_schema =  types.StructType([\n",
    "    types.StructField('hvfhs_license_num',types.StringType(),True),\n",
    "    types.StructField('dispatching_base_num',types.StringType(),True),\n",
    "    types.StructField('pickup_datetime',types.TimestampType(),True),\n",
    "    types.StructField('dropoff_datetime',types.TimestampType(),True),\n",
    "    types.StructField('PULocationID',types.IntegerType(),True),\n",
    "    types.StructField('DOLocationID',types.IntegerType(),True),\n",
    "    types.StructField('SR_Flag',types.StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb691ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "month = 2\n",
    "\n",
    "\n",
    "\n",
    "input_path = f'data/raw/fhvhv/{year}/{month:02d}/'\n",
    "output_path = f'data/pq/fhvhv/{year}/{month:02d}/'\n",
    "\n",
    "df_fhvhv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(fhvhv_schema) \\\n",
    "    .csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c03d83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11613942"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhvhv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473156a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhvhv = df_fhvhv.repartition(24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408ff3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhvhv.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "211fe1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhvhv \\\n",
    "    .write.parquet(output_path,mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "544755ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211M\t./data/pq/fhvhv/2021/02\r\n"
     ]
    }
   ],
   "source": [
    "!du -h ./data/pq/fhvhv/2021/02 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0bc8e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 209M\r\n",
      "   0 _SUCCESS\r\n",
      "8.7M part-00000-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00001-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00002-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00003-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00004-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00005-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00006-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00007-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00008-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00009-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00010-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00011-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00012-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00013-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00014-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00015-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00016-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00017-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00018-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00019-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00020-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00021-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00022-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n",
      "8.7M part-00023-f85e9f4b-4370-4500-af94-bb4b7110dcb5-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "!ls -hs ./data/pq/fhvhv/2021/02 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f436f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './data/pq/fhvhv/2021/02'\n",
    "\n",
    "df = spark.read \\\n",
    "    .parquet(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b164c40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eb28495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(pickup_datetime=datetime.datetime(2021, 2, 5, 18, 53, 32)),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 2, 3, 20, 4, 21)),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 2, 4, 0, 26, 3)),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 2, 5, 8, 21, 19)),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 2, 1, 21, 54, 16))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(col(\"pickup_datetime\")).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "233e7e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367174"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(col(\"pickup_datetime\").between('2021-02-15','2021-02-16')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4f840c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367165"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"pickup_datetime > date'2021-02-15'\").filter(\"pickup_datetime < date'2021-02-16'\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bfbcc9",
   "metadata": {},
   "source": [
    "# Question 4. Longest trip for each day\n",
    "Now calculate the duration for each trip.\n",
    "\n",
    "Trip starting on which day was the longest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b166604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------+\n",
      "|        pickup_date|max_trip_duration_seconds|\n",
      "+-------------------+-------------------------+\n",
      "|2021-02-11 00:00:00|                    75540|\n",
      "|2021-02-17 00:00:00|                    57221|\n",
      "|2021-02-20 00:00:00|                    44039|\n",
      "|2021-02-03 00:00:00|                    40653|\n",
      "|2021-02-19 00:00:00|                    37577|\n",
      "+-------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate Time difference in Seconds\n",
    "input_path = './data/pq/fhvhv/2021/02'\n",
    "\n",
    "df = spark.read \\\n",
    "    .parquet(input_path)\n",
    "\n",
    "\n",
    "df2 = df.withColumn('pickup_date', F.date_trunc('DAY', col('pickup_datetime'))) \\\n",
    "        .withColumn('trip_duration_seconds',col(\"dropoff_datetime\").cast(\"long\") - col('pickup_datetime').cast(\"long\")) \\\n",
    "        .select('pickup_date','trip_duration_seconds')\n",
    "  \n",
    "df2.groupBy('pickup_date').agg(F.max('trip_duration_seconds').alias('max_trip_duration_seconds')) \\\n",
    "            .orderBy(F.desc('max_trip_duration_seconds')).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ff27a2",
   "metadata": {},
   "source": [
    "# Question 5. Most frequent dispatching_base_num\n",
    "\n",
    "Now find the most frequently occurring dispatching_base_num in this dataset.\n",
    "\n",
    "How many stages does this spark job has?\n",
    "\n",
    "Note: the answer may depend on how you write the query, so there are multiple correct answers. \n",
    "Select the one you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e185f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './data/pq/fhvhv/2021/02'\n",
    "\n",
    "df = spark.read \\\n",
    "    .parquet(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f14ca672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B02510', trip_count=3233664)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('dispatching_base_num')\\\n",
    "    .agg(F.count(col('pickup_datetime')).alias('trip_count')) \\\n",
    "        .orderBy(F.desc('trip_count')) \\\n",
    "            .take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f649429",
   "metadata": {},
   "source": [
    "Skipped Stages: 73\n",
    "Completed Stages: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f30457",
   "metadata": {},
   "source": [
    "![Details of Job](hw5_q5_stages.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4afdc",
   "metadata": {},
   "source": [
    "# Question 6. Most common locations pair\n",
    "Find the most common pickup-dropoff pair.\n",
    "\n",
    "For example:\n",
    "\"Jamaica Bay / Clinton East\"\n",
    "\n",
    "Enter two zone names separated by a slash\n",
    "If any of the zone names are unknown (missing), use \"Unknown\". For example, \"Unknown / Clinton East\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "524f34ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0003|              B02866|2021-02-05 18:53:32|2021-02-05 19:00:26|          91|         155|   null|\n",
      "|           HV0003|              B02876|2021-02-03 20:04:21|2021-02-03 20:19:09|          29|         154|   null|\n",
      "|           HV0003|              B02888|2021-02-04 00:26:03|2021-02-04 00:40:33|         151|         229|   null|\n",
      "|           HV0003|              B02887|2021-02-05 08:21:19|2021-02-05 08:26:49|         215|         215|   null|\n",
      "|           HV0003|              B02764|2021-02-01 21:54:16|2021-02-01 22:09:23|          25|          49|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_path = './data/pq/fhvhv/2021/02'\n",
    "\n",
    "df = spark.read \\\n",
    "    .parquet(input_path)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18735599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lkup = spark.read.parquet('zones')\n",
    "lkup = lkup.filter(~(col('Borough') == 'Unknown'))\n",
    "lkup.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b78e0b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lkup.printSchema()\n",
    "lkup = lkup.withColumn(\"LocationID\",col(\"LocationID\").cast(types.IntegerType()))\n",
    "lkup.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f1ed3816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(pickup_dropoff_pair='East New York / East New York', trip_count=45041)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = df.join(lkup,df[\"PULocationID\"] == lkup[\"LocationID\"])\\\n",
    ".withColumn('pickup_zone',col('zone'))\\\n",
    ".select('pickup_zone','DOLocationID')\\\n",
    ".join(lkup,df[\"DOLocationID\"] == lkup[\"LocationID\"])\\\n",
    ".withColumn('drop_off_zone',col('zone'))\\\n",
    ".select('pickup_zone','drop_off_zone')\n",
    "\n",
    "trips.withColumn('pickup_dropoff_pair', F.concat_ws(\" / \", col('pickup_zone'),col('drop_off_zone'))) \\\n",
    "    .groupBy('pickup_dropoff_pair').agg(F.count('pickup_dropoff_pair').alias('trip_count')) \\\n",
    "        .orderBy(F.desc('trip_count')) \\\n",
    "        .take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac92e1",
   "metadata": {},
   "source": [
    "# Bonus question. Join type\n",
    "(not graded)\n",
    "\n",
    "For finding the answer to Q6, you'll need to perform a join.\n",
    "\n",
    "What type of join is it?\n",
    "\n",
    "And how many stages your spark job has?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6379dfe",
   "metadata": {},
   "source": [
    "![Trip Pair Count](hw5_q6_stages.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f2fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
